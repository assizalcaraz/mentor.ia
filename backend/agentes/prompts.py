# agentes/prompts.py

BASE_PROMPT = """\
Tu tarea es responder exclusivamente en formato JSON v√°lido y sin explicaciones adicionales. 
No incluyas texto antes ni despu√©s del bloque JSON. 
Asegurate de que sea un JSON parseable por una m√°quina. 
"""

def prompt_arquitecto(objetivo, contexto="", temperatura=0.2, modelo="codellama:7b-instruct"):
    full_prompt = f"""{BASE_PROMPT}
Objetivo: {objetivo}
{f'Contexto: {contexto}' if contexto else ''}

Devolveme una lista de tareas JSON con los campos:
- tarea
- tipo
- prioridad (1 a 5)
- depende_de (lista de otras tareas)

Ejemplo:
[
  {{
    "tarea": "Investigar conceptos clave",
    "tipo": "investigaci√≥n",
    "prioridad": 1,
    "depende_de": []
  }},
  {{
    "tarea": "Escribir resumen",
    "tipo": "redacci√≥n",
    "prioridad": 2,
    "depende_de": ["Investigar conceptos clave"]
  }}
]
"""
    return {
        "model": modelo,
        "prompt": full_prompt,
        "temperature": temperatura,
        "stream": False
    }


def prompt_codigo(prompt_usuario, temperatura=0.2, modelo="codellama:7b-instruct"):
    prompt = (
        "Respond√© solo con el c√≥digo, en formato JSON si es posible. "
        "No expliques nada. No incluyas encabezados ni texto fuera del bloque de c√≥digo.\n"
        f"INSTRUCCI√ìN: {prompt_usuario}"
    )
    return {
        "model": modelo,
        "prompt": prompt,
        "temperature": temperatura,
        "stream": False
    }


def prompt_constructor(objetivo, contexto="", temperatura=0.2, modelo="phind-codellama"):
    full_prompt = f"""{BASE_PROMPT}
Analiz√° el siguiente objetivo: "{objetivo}"
{f'Contexto: {contexto}' if contexto else ''}

Devuelve una lista JSON de tareas necesarias para cumplirlo. 
Cada tarea debe tener: id, descripcion, prioridad (alta/media/baja).

Formato esperado:
[
  {{
    "id": 1,
    "descripcion": "Inicializar repositorio git",
    "prioridad": "alta"
  }},
  ...
]"""
    return {
        "model": modelo,
        "prompt": full_prompt,
        "temperature": temperatura,
        "stream": False
    }

def prompt_evaluacion(texto, criterio="calidad t√©cnica", temperatura=0.2, modelo="phind-codellama"):
    full_prompt = f"""{BASE_PROMPT}
Evalu√° el siguiente texto seg√∫n el criterio '{criterio}'.

Texto:
{texto}

Formato esperado:
{{
  "criterio": "{criterio}",
  "calificacion": <n√∫mero del 1 al 10>,
  "justificacion": "<breve justificaci√≥n>"
}}"""
    return {
        "model": modelo,
        "prompt": full_prompt,
        "temperature": temperatura,
        "stream": False
    }

# üí° Extra: para casos de metadata, info estructurada, etc.
def prompt_info(categoria, temperatura=0.2, modelo="phind-codellama"):
    full_prompt = f"""{BASE_PROMPT}
Devolveme informaci√≥n relevante sobre la categor√≠a "{categoria}" en formato JSON.

Formato esperado:
{{
  "categoria": "{categoria}",
  "datos": [
    "...",
    "..."
  ]
}}"""
    return {
        "model": modelo,
        "prompt": full_prompt,
        "temperature": temperatura,
        "stream": False
    }
